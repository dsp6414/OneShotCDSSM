{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "\n",
    "def tokenizer(text, alpha_only=True): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text) if (not alpha_only or tok.is_alpha )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x1, x2, dim=1, eps=1e-8): # support for old versions of Pytorch\n",
    "    r\"\"\"Returns cosine similarity between x1 and x2, computed along dim.\n",
    "\n",
    "    .. math ::\n",
    "        \\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}\n",
    "\n",
    "    Args:\n",
    "        x1 (Tensor): First input.\n",
    "        x2 (Tensor): Second input (of size matching x1).\n",
    "        dim (int, optional): Dimension of vectors. Default: 1\n",
    "        eps (float, optional): Small value to avoid division by zero.\n",
    "            Default: 1e-8\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(\\ast_1, D, \\ast_2)` where D is at position `dim`.\n",
    "        - Output: :math:`(\\ast_1, \\ast_2)` where 1 is at position `dim`.\n",
    "\n",
    "    Example::\n",
    "\n",
    "        >>> input1 = torch.randn(100, 128)\n",
    "        >>> input2 = torch.randn(100, 128)\n",
    "        >>> output = F.cosine_similarity(input1, input2)\n",
    "        >>> print(output)\n",
    "    \"\"\"\n",
    "    w12 = torch.sum(x1 * x2, dim)\n",
    "    w1 = torch.norm(x1, 2, dim)\n",
    "    w2 = torch.norm(x2, 2, dim)\n",
    "    return w12 / (w1 * w2).clamp(min=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(distances, target, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    :param distances 1d Tensor shape: (num_examples, )\n",
    "    :param target 1d Tensor shape: (num_examples, )\n",
    "    \"\"\"\n",
    "\n",
    "    diff = torch.abs(distances - target)\n",
    "    return torch.sum(diff[diff > alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list(batch, pad=None):\n",
    "    if pad is None:\n",
    "        pad = list\n",
    "    batch_lengths = list(map(len, batch))\n",
    "    max_len = max(batch_lengths)\n",
    "\n",
    "    for seq, length in zip(batch, batch_lengths):\n",
    "        diff = max_len - length\n",
    "        for idx in range(diff):\n",
    "            seq.append(pad())\n",
    "\n",
    "    return batch\n",
    "\n",
    "\n",
    "def pad_numpy(sequences, max_len=None):\n",
    "    \"\"\"\n",
    "    :param sequences - list of lists\n",
    "    \"\"\"\n",
    "    seq_lengths = list(map(len, sequences))\n",
    "    max_len = max_len or max(seq_lengths)\n",
    "\n",
    "    seq_tensor = np.zeros((len(sequences), max_len), dtype=int)\n",
    "\n",
    "    for idx, (seq, seqlen) in enumerate(zip(sequences, seq_lengths)):\n",
    "        seq_tensor[idx, :seqlen] = np.array(seq, dtype=int)\n",
    "\n",
    "    return seq_tensor, seq_lengths\n",
    "\n",
    "\n",
    "def pad_batch(batch):\n",
    "    max_word_len = max(map(lambda x: max(map(len, x)), batch))\n",
    "    return np.stack(map(lambda x: pad_numpy(x, max_word_len)[0], pad_list(batch)))\n",
    "\n",
    "\n",
    "def encode_ngrams(tokens, dict_size):\n",
    "    words = []\n",
    "    for token in tokens:\n",
    "        token = \" {} \".format(token)\n",
    "        word_ngrams = []\n",
    "        for ngram in ngrams(token, 3):\n",
    "            crc32_hash = zlib.crc32(str(ngram).encode())\n",
    "            \n",
    "            word_ngrams.append(crc32_hash % dict_size)\n",
    "            \n",
    "        words.append(word_ngrams)\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "def encode_texts(texts, dict_size):    \n",
    "    return list(map(\n",
    "        lambda x: encode_ngrams(x, dict_size),\n",
    "        map(\n",
    "            tokenizer,\n",
    "            texts\n",
    "        )\n",
    "    ))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseLinear(nn.Linear):\n",
    "    def __init__(self, dict_size, out_features, bias=True):\n",
    "        super(SparseLinear, self).__init__(in_features=dict_size, out_features=out_features, bias=bias)\n",
    "    \n",
    "    def forward(self, inpt):\n",
    "        res = torch.index_select(self.weight.t(), 0, inpt.view(-1))\n",
    "        res = res.view(-1, inpt.shape[-1], self.out_features)\n",
    "        res = res.sum(dim=1)\n",
    "        res = res.view(*inpt.shape[:-1], self.out_features)\n",
    "        \n",
    "        if self.bias is not None:\n",
    "            res = res + self.bias\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CDSSM(nn.Module):\n",
    "    \n",
    "    conv_input_size = 500\n",
    "    conv_out_size = 300\n",
    "    out_size = 128\n",
    "    window = 3\n",
    "    embedding_size = 20000\n",
    "    \n",
    "    def __init__(self, is_cuda=False):\n",
    "        super(CDSSM, self).__init__()\n",
    "        \n",
    "        self.is_cuda = is_cuda\n",
    "        \n",
    "        self.sparse_linear = SparseLinear(dict_size=self.embedding_size, out_features=self.conv_input_size)\n",
    "        self.conv_nn = torch.nn.Conv1d(self.conv_input_size, self.conv_out_size, self.window)\n",
    "        self.feed_forvard = nn.Linear(in_features=self.conv_out_size, out_features=self.out_size)\n",
    "        \n",
    "        if self.is_cuda:\n",
    "            self.cuda()\n",
    "    \n",
    "    def process_sentence(self, sentences):\n",
    "        \"\"\"\n",
    "        :param sentences Tensor (batch_size, sentence_length, word_depth)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compress sparse ngram representation into dense vectors \n",
    "        sentences = F.relu(self.sparse_linear(sentences))\n",
    "        \n",
    "        # Prepare for convolution and apply it.\n",
    "        # Combine 3-word window into single vector\n",
    "        sentences = sentences.transpose(1, 2)\n",
    "        \n",
    "        conv_embedding = F.relu(self.conv_nn(sentences))\n",
    "        \n",
    "        # Apply max-pooling to compress variable-length sequence of 3-word vectors into single document vector\n",
    "        convolutions_size = conv_embedding.size()[2]\n",
    "        max_pooling = F.max_pool1d(conv_embedding, kernel_size=convolutions_size).view(-1, self.conv_out_size)\n",
    "        \n",
    "        # Compress pooled representation even more\n",
    "        res = F.relu(self.feed_forvard(max_pooling))\n",
    "        \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"One (1) guide and one (1) spotter per hunter are generaly used. Top off this hunt with opportunities for \" \\\n",
    "        \"trophy XXXXX. (12 day hunts) Home | Hunts | Camps | News | Gallery | Links | Contact Copyright  2007 Bugle \" \\\n",
    "        \"Basin Outfitters. \"\n",
    "positive = \"Wolverine Creek Outfitters . Founded in the mid 1940s, Wolverine Creek have consistently provided hunters \" \\\n",
    "           \"the opportunity to harvest trophy bull elk , moose , XXXXX and bighorn sheep . I met up with Wolverine \" \\\n",
    "           \"Creek s master hunter  Ryan Lakovitch  again at this years SHOT Show . Ryan \"\n",
    "negative = \"2011-08-19 14:45:00 in the \\\" performance \\\" category Image by \\\"exfordy\\\" on Flickr End Point recently \" \\\n",
    "           \"started working with a new client (a startup in XXXXX, cannot name names, etc.) who is using PostgreSQL \" \\\n",
    "           \"because of the great success some of the people starting the company have had with Postgres \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CDSSM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = pad_batch(encode_texts([query, positive, negative], 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 208,  130,  919,  ...,    0,    0,    0],\n",
       "         [ 642,  795,  277,  ...,    0,    0,    0],\n",
       "         [ 772,  792,  225,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0,  ...,    0,    0,    0],\n",
       "         [   0,    0,    0,  ...,    0,    0,    0],\n",
       "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
       "\n",
       "        [[ 529,  764,  739,  ...,    0,    0,    0],\n",
       "         [ 251,  101,    5,  ...,    0,    0,    0],\n",
       "         [ 825,  560,  297,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [   0,    0,    0,  ...,    0,    0,    0],\n",
       "         [   0,    0,    0,  ...,    0,    0,    0],\n",
       "         [   0,    0,    0,  ...,    0,    0,    0]],\n",
       "\n",
       "        [[ 609,  929,    0,  ...,    0,    0,    0],\n",
       "         [ 193,  377,  426,  ...,    0,    0,    0],\n",
       "         [ 248,  443,  660,  ...,  817,    0,    0],\n",
       "         ...,\n",
       "         [ 402,  316,  764,  ...,    0,    0,    0],\n",
       "         [ 949,   30,  602,  ...,    0,    0,    0],\n",
       "         [ 768,  233,  282,  ...,    0,    0,    0]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Variable(torch.from_numpy(batch)); inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 47, 500])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       [[ 2.3946,  0.0000,  0.0000,  5.6208,  0.0000,  4.8701,  4.0002,\n",
       "          1.3212,  0.0000,  5.1779,  3.3613,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  2.8338,  0.0000,  1.6666,  0.0000,  2.5371,  3.3030,\n",
       "          0.0000,  6.9933,  0.0000,  1.5986,  3.5640,  0.0000,  0.0000,\n",
       "          0.0000,  1.5470,  0.0000,  0.0000,  2.9109,  6.1972,  2.0791,\n",
       "          0.0000,  3.6186,  0.0000,  0.0000,  2.3091,  0.0000,  2.8679,\n",
       "          4.1418,  5.2189,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          4.9565,  0.0000,  4.0952,  4.4193,  0.0000,  0.0000,  0.0000,\n",
       "          1.9381,  5.9366,  0.0000,  3.4665,  2.0813,  4.5665,  0.0000,\n",
       "          0.0000,  2.8416,  0.0000,  0.8578,  2.4593,  0.0000,  0.0000,\n",
       "          1.7891,  0.0000,  0.0000,  0.0000,  3.5063,  1.5199,  0.0000,\n",
       "          2.0778,  0.0000,  3.9739,  0.2569,  2.5575,  3.1236,  3.2029,\n",
       "          0.0000,  0.0000,  4.5519,  1.4453,  0.0000,  6.4522,  0.0000,\n",
       "          0.0000,  0.0000,  1.6154,  1.4572,  3.2646,  0.0000,  0.0000,\n",
       "          6.0595,  3.3565,  1.8902,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          4.8075,  0.0000,  0.0000,  4.3823,  0.0000,  0.7950,  3.4290,\n",
       "          0.0000,  1.5382,  3.2532,  2.9240,  0.0000,  0.0000,  0.2253,\n",
       "          3.5637,  1.9510,  0.0000,  1.3303,  5.9243,  0.0000,  0.0000,\n",
       "          0.0000,  3.8004],\n",
       "        [ 2.1607,  0.0000,  0.0000,  5.7960,  0.0000,  4.9638,  4.2693,\n",
       "          1.2103,  0.0000,  5.0402,  3.2076,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  2.8904,  0.0000,  1.5568,  0.0000,  2.6684,  3.3629,\n",
       "          0.0000,  6.8602,  0.0000,  1.4411,  3.7023,  0.0000,  0.0000,\n",
       "          0.0000,  1.5941,  0.0000,  0.0000,  2.8875,  6.3440,  1.9648,\n",
       "          0.0000,  3.6365,  0.0000,  0.0000,  2.0059,  0.0000,  2.9823,\n",
       "          4.2225,  5.2949,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          5.0885,  0.1647,  3.6544,  4.4830,  0.0000,  0.0000,  0.0000,\n",
       "          1.8895,  5.9308,  0.0000,  3.4880,  2.0870,  4.5303,  0.0000,\n",
       "          0.0000,  2.8437,  0.0000,  1.1548,  2.3681,  0.0000,  0.0000,\n",
       "          1.6925,  0.0000,  0.0000,  0.0000,  3.5720,  1.6587,  0.0000,\n",
       "          1.9215,  0.0000,  4.2157,  0.5188,  2.3995,  3.2023,  3.1858,\n",
       "          0.0000,  0.0000,  4.5738,  1.2477,  0.0000,  6.4262,  0.0000,\n",
       "          0.0000,  0.0000,  1.6397,  1.6972,  3.2823,  0.0000,  0.0000,\n",
       "          5.8354,  3.5878,  1.7715,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          4.5380,  0.0000,  0.0000,  4.3651,  0.0000,  0.8797,  3.5792,\n",
       "          0.0000,  1.6809,  3.0393,  2.7548,  0.0000,  0.0000,  0.1831,\n",
       "          3.5555,  1.9181,  0.0000,  1.1820,  6.4770,  0.0000,  0.0000,\n",
       "          0.0000,  3.9126],\n",
       "        [ 1.9944,  0.0000,  0.0000,  5.8905,  0.0000,  4.7286,  4.3486,\n",
       "          1.3670,  0.0000,  5.0481,  3.0672,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  3.0591,  0.0000,  1.7671,  0.0000,  2.6127,  3.3110,\n",
       "          0.0000,  6.7724,  0.0000,  1.7613,  3.5786,  0.0000,  0.0000,\n",
       "          0.0000,  1.5512,  0.0000,  0.0000,  3.0819,  6.1111,  2.0634,\n",
       "          0.0000,  3.7702,  0.0000,  0.0000,  1.9031,  0.0000,  2.7093,\n",
       "          4.1016,  5.1783,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          5.1464,  0.0000,  3.9617,  4.2008,  0.0000,  0.0000,  0.0000,\n",
       "          1.7839,  5.8122,  0.0000,  3.2593,  1.9719,  4.6232,  0.0000,\n",
       "          0.0000,  2.7916,  0.0000,  1.2341,  2.4152,  0.0000,  0.0000,\n",
       "          1.6852,  0.0000,  0.0000,  0.0000,  3.3783,  1.6082,  0.0000,\n",
       "          2.1714,  0.0000,  4.0761,  0.5382,  2.5096,  3.2194,  3.2663,\n",
       "          0.0000,  0.0000,  4.3966,  1.4618,  0.0000,  6.3612,  0.0000,\n",
       "          0.0000,  0.0000,  1.5656,  1.7130,  3.1042,  0.0000,  0.0000,\n",
       "          5.8397,  3.1364,  1.9313,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          4.6804,  0.0000,  0.0000,  4.3061,  0.0000,  1.2544,  3.6540,\n",
       "          0.0000,  1.7468,  3.1090,  2.8582,  0.0000,  0.0000,  0.3467,\n",
       "          3.4578,  2.1460,  0.0000,  1.3823,  6.2254,  0.0000,  0.0000,\n",
       "          0.0000,  3.7995]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.process_sentence(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.FloatTensor([\n",
    "    [1, 1],\n",
    "    [-1, 1],\n",
    "    [0, 1]\n",
    "])\n",
    "\n",
    "b = torch.FloatTensor([\n",
    "    [-1, -1],\n",
    "    [-2, 2],\n",
    "    [1, 1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = torch.FloatTensor([\n",
    "    1,\n",
    "    -1,\n",
    "    1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = torch.abs(cosine_similarity(a, b) - exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(diff[diff > 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785407753397449"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.acos(0.7071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.cos(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
